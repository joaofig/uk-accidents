{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads the CSV files and appends them into a single DataFrame\"\"\"\n",
    "    column_types = {'Accident_Index': np.string_, 'LSOA_of_Accident_Location': np.string_}\n",
    "    uk2015 = pd.read_csv(\"data/DfTRoadSafety_Accidents_2015.csv\", dtype=column_types)\n",
    "    uk2016 = pd.read_csv(\"data/dftRoadSafety_Accidents_2016.csv\", dtype=column_types)\n",
    "    return uk2015.append(uk2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from functools import partial\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "\n",
    "def buffer_in_meters(lng, lat, radius):\n",
    "    proj_meters = pyproj.Proj(init='epsg:3857')\n",
    "    proj_latlng = pyproj.Proj(init='epsg:4326')\n",
    "    \n",
    "    project_to_meters = partial(pyproj.transform, proj_latlng, proj_meters)\n",
    "    project_to_latlng = partial(pyproj.transform, proj_meters, proj_latlng)\n",
    "    \n",
    "    pt_latlng = Point(lng, lat)\n",
    "    pt_meters = transform(project_to_meters, pt_latlng)\n",
    "    \n",
    "    buffer_meters = pt_meters.buffer(radius)\n",
    "    buffer_latlng = transform(project_to_latlng, buffer_meters)\n",
    "    return buffer_latlng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_acc = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concave_hull(points, k):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop invalid rows\n",
    "uk_acc.dropna()\n",
    "\n",
    "uk_acc = uk_acc.loc[uk_acc.Latitude <=  90.0]\n",
    "uk_acc = uk_acc.loc[uk_acc.Latitude >= -90.0]\n",
    "\n",
    "uk_acc = uk_acc.loc[uk_acc.Longitude <=  180.0]\n",
    "uk_acc = uk_acc.loc[uk_acc.Longitude >= -180.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the radian longitude and latitude columns\n",
    "import math\n",
    "\n",
    "uk_acc['rad_lng'] = uk_acc['Longitude'] * math.pi / 180.0\n",
    "uk_acc['rad_lat'] = uk_acc['Latitude'] * math.pi / 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "eps_in_meters = 50.0\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "earth_perimeter = 40070000.0  # In meters\n",
    "eps_in_radians = eps_in_meters / earth_perimeter * (2 * math.pi)\n",
    "\n",
    "uk_acc['cluster'] = DBSCAN(eps=eps_in_radians, min_samples=num_samples, metric='haversine').fit_predict(uk_acc[['rad_lat', 'rad_lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the observations by cluster identifier\n",
    "groups = uk_acc.groupby('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of cluster blobs\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "clusters = list()\n",
    "blobs = list()\n",
    "counts = list()\n",
    "\n",
    "for cluster_id, points in groups:\n",
    "    if cluster_id >= 0:\n",
    "        buffer_radius = eps_in_meters * 0.6\n",
    "        buffers = [buffer_in_meters(lon, lat, buffer_radius) for lon, lat in zip(points['Longitude'], points['Latitude'])]\n",
    "        blob = cascaded_union(buffers)\n",
    "        blobs.append(blob)\n",
    "        clusters.append(cluster_id)\n",
    "        counts.append(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GeoDataFrame from the cluster numbers and blobs\n",
    "data = { 'cluster': clusters, 'polygon': blobs, 'count': counts }\n",
    "\n",
    "cluster_gdf = gpd.GeoDataFrame(pd.DataFrame(data), geometry='polygon')\n",
    "cluster_gdf.crs = {'init': 'epsg:4326'}\n",
    "\n",
    "ax = cluster_gdf.geometry.plot(linewidth=2.0, color='red', edgecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplleaflet\n",
    "mplleaflet.show(fig=ax.figure, tiles='cartodb_positron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
